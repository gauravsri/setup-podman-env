# =============================================================================
# M4 MacBook Pro Optimized Configuration (16GB RAM, 10 cores)
# =============================================================================
# Hardware: Apple M4 chip with 4 performance + 6 efficiency cores
# Memory: 16 GB LPDDR5
# Storage: 512GB SSD with 180GB free
#
# Resource allocation strategy:
# - Reserve 4GB for macOS
# - Use 12GB for containers
# - Use 8 cores (reserve 2 for system)
# - Optimize for fast SSD I/O
# =============================================================================

# Project Configuration
PROJECT_NAME="hbase-delta-converter"
PROJECT_DESCRIPTION="HBase to Delta Lake Converter - M4 Optimized"

# Network Configuration
NETWORK_NAME="${PROJECT_NAME}-network"

# =============================================================================
# SERVICE SELECTION
# =============================================================================
ENABLED_SERVICES="minio,spark,hbase"

# =============================================================================
# MINIO CONFIGURATION (S3-Compatible Storage)
# =============================================================================
MINIO_CONTAINER_NAME="${PROJECT_NAME}-minio"
MINIO_IMAGE="quay.io/minio/minio:latest"
MINIO_PORT="9000"
MINIO_CONSOLE_PORT="9001"
MINIO_VOLUME_NAME="minio-data"
MINIO_MEMORY="512m"
MINIO_ROOT_USER="minioadmin"
MINIO_ROOT_PASSWORD="minioadmin"

# =============================================================================
# APACHE SPARK CONFIGURATION (Optimized for M4)
# =============================================================================
SPARK_MASTER_CONTAINER_NAME="${PROJECT_NAME}-spark-master"
SPARK_WORKER_CONTAINER_PREFIX="${PROJECT_NAME}-spark-worker"
SPARK_IMAGE="bitnami/spark:3.3.2"
SPARK_MASTER_PORT="7077"
SPARK_MASTER_WEB_PORT="8070"
SPARK_WORKER_WEB_PORT_BASE="8200"

# Optimized for M4 MacBook Pro
SPARK_MEMORY="2g"                            # Master: 2GB
SPARK_WORKER_MEMORY="4g"                     # Each worker: 4GB
SPARK_WORKER_CORES="4"                       # Use 4 performance cores per worker
SPARK_WORKER_COUNT="2"                       # 2 workers = 8GB total worker memory
SPARK_VOLUME_NAME="spark-data"

# Spark Job Execution Settings (for local[*] mode)
SPARK_DRIVER_MEMORY="6g"                     # Driver memory for local jobs
SPARK_EXECUTOR_MEMORY="4g"                   # Executor memory for local jobs
SPARK_LOCAL_CORES="8"                        # Use 8 cores for local mode
SPARK_SHUFFLE_PARTITIONS="16"                # 2x CPU cores

# =============================================================================
# HBASE CONFIGURATION (Optimized for M4)
# =============================================================================
HBASE_CONTAINER_NAME="${PROJECT_NAME}-hbase"
HBASE_IMAGE="harisekhon/hbase:2.4"
HBASE_MASTER_PORT="16000"
HBASE_MASTER_WEB_PORT="16010"
HBASE_REGION_PORT="16020"
HBASE_REGION_WEB_PORT="16030"
HBASE_ZOOKEEPER_PORT="2181"
HBASE_VOLUME_NAME="hbase-data"
HBASE_MEMORY="2g"                            # HBase memory limit
HBASE_HEAP_SIZE="1g"                         # HBase heap size

# =============================================================================
# DREMIO CONFIGURATION (Optional - for Delta Lake queries)
# =============================================================================
DREMIO_CONTAINER_NAME="${PROJECT_NAME}-dremio"
DREMIO_IMAGE="dremio/dremio-oss:latest"
DREMIO_HTTP_PORT="9047"
DREMIO_JDBC_PORT="31010"
DREMIO_VOLUME_NAME="dremio-data"
DREMIO_MEMORY="2g"
DREMIO_STARTUP_TIMEOUT="720"

# =============================================================================
# RESOURCE LIMITS (M4 MacBook Pro)
# =============================================================================
# Memory usage breakdown:
# - MinIO: 512m
# - HBase: 2g
# - Spark Master: 2g
# - Spark Workers: 2x 4g = 8g
# - Total: ~12.5GB (leaves 3.5GB for macOS)
#
# For local Spark jobs (without cluster):
# - Spark Driver: 6g
# - MinIO: 512m
# - HBase: 2g
# - Total: ~8.5GB (leaves 7.5GB for macOS)

BASIC_SETUP_MEMORY="2.5GB"                   # MinIO + HBase
FULL_SETUP_MEMORY="12.5GB"                   # Full stack with Spark cluster

# =============================================================================
# DEVELOPMENT FLAGS
# =============================================================================
DEVELOPMENT_MODE="true"
AUTO_CREATE_VOLUMES="true"
CLEANUP_ON_EXIT="false"
VERBOSE_LOGGING="false"
DEFAULT_LOG_LINES="50"

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================
# Podman/Docker settings
PODMAN_MAX_MEMORY="12g"                      # Max memory for all containers
PODMAN_MAX_CPUS="8"                          # Max CPUs for containers

# Spark tuning for local development
SPARK_SERIALIZER="org.apache.spark.serializer.KryoSerializer"
SPARK_SQL_ADAPTIVE_ENABLED="true"
SPARK_SQL_ADAPTIVE_COALESCE_PARTITIONS_ENABLED="true"
SPARK_DYNAMIC_ALLOCATION_ENABLED="false"     # Disabled for standalone mode

# I/O optimization for M4's fast SSD
SPARK_LOCAL_DIR="/tmp/spark-temp"
HBASE_TMP_DIR="/tmp/hbase-temp"

# =============================================================================
# PROJECT-SPECIFIC PATHS
# =============================================================================
PROJECT_DIR="/Users/gaurav/workspace/claude/hbase-delta-converter"
SNAPSHOT_DIR="${PROJECT_DIR}/hbase-snapshots"
DELTA_OUTPUT_DIR="${PROJECT_DIR}/delta-output"
CONFIG_DIR="${PROJECT_DIR}/config"
